#   /*
#    * Copyright (c) 2022-2025 KCloud-Platform-IoT Author or Authors. All Rights Reserved.
#    *
#    * Licensed under the Apache License, Version 2.0 (the "License");
#    * you may not use this file except in compliance with the License.
#    * You may obtain a copy of the License at
#    *
#    *   http://www.apache.org/licenses/LICENSE-2.0
#    *
#    * Unless required by applicable law or agreed to in writing, software
#    * distributed under the License is distributed on an "AS IS" BASIS,
#    * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    * See the License for the specific language governing permissions and
#    * limitations under the License.
#    *
#    */
# server
server:
  port: ${SERVER_PORT:10003}
  ssl:
    # 开启证书
    enabled: @SSL-ENABLED@
    # 证书位置
    key-store: classpath:scg-keystore.p12
    # 证书别名
    key-alias: ${spring.application.name}
    # 秘钥类型
    key-store-type: PKCS12
    # 证书密码
    key-store-password: laokou
  http2:
    enabled: @SSL-ENABLED@
  forward-headers-strategy: framework
  shutdown: graceful
# spring
spring:
  application:
    name: ${SERVICE_ID:laokou-logstash}
  profiles:
    active: @PROFILE-ACTIVE@
  data:
    redis:
      client-type: lettuce
      host: redis
      port: 6379
      password: ENC(BhsqlMbKjWVxPseo9OX8osLuL2Y4rWfGTyBRXaZTsAdzZ1Z4rBewBmoXjf2Hnu4o)
      connect-timeout: 60000ms #连接超时时长（毫秒）
      timeout: 60000ms #超时时长（毫秒）
      lettuce:
        pool:
          max-active: -1 #连接池最大连接数（使用负值表示无极限）
          max-wait: -1 #连接池最大阻塞等待时间（使用负值表示没有限制）
          max-idle: 500 #连接池最大空闲连接
          min-idle: 200 #连接池最小空间连接
  # elasticsearch
  elasticsearch:
    uris:
      - https://elasticsearch:9200
    username: ENC(svQedUe/LhX4+kE58LA73GTbkn0xR1Nz4P9hIalcloHMkQ8BCur8LiptBZ9DI78f)
    password: ENC(BhsqlMbKjWVxPseo9OX8osLuL2Y4rWfGTyBRXaZTsAdzZ1Z4rBewBmoXjf2Hnu4o)
    connection-timeout: 30s
    socket-timeout: 30s
  kafka:
    bootstrap-servers: kafka:9092
    consumer:
      group-id: laokou_trace_consumer_group
      # 禁用自动提交（按周期）已消费offset
      enable-auto-commit: false
      # 单次poll()调用返回的记录数
      max-poll-records: 50
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      # 发生错误后，消息重发的次数。
      retries: 5
      #当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。
      batch-size: 16384
      # 设置生产者内存缓冲区的大小。
      buffer-memory: 33554432
      # 键的序列化方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 值的序列化方式
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # acks=0 ： 生产者在成功写入消息之前不会等待任何来自服务器的响应。
      # acks=1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
      # acks=all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
      acks: 0
    listener:
      # 在侦听器容器中运行的线程数。
      concurrency: 5
      # listner负责ack，每调用一次，就立即commit
      ack-mode: manual
      # 批量batch类型
      type: batch
      # topic不存在报错
      missing-topics-fatal: false
  cloud:
    # loadbalancer
    loadbalancer:
      nacos:
        enabled: true
    inetutils:
      ignored-interfaces:
        - docker0
        - veth.*
  threads:
    virtual:
      enabled: true

logging:
  config: classpath:log4j2-@PROFILE-ACTIVE@.xml

storage:
  type: elasticsearch

loki:
  url: http://loki:3100/loki/api/v1/push
jasypt:
  encryptor:
    password: laokou
